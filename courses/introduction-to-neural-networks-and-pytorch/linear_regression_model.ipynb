{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression 1D: Prediction</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objective</h2><ul><li> How to make the prediction for multiple inputs.</li><li> How to use linear class to build more complex models.</li><li> How to build a custom module.</li></ul> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, we will  review how to make a prediction in several different ways by using PyTorch.</h2>\n",
    "<ul>\n",
    "    <li><a href=\"#Prediction\">Prediction</a></li>\n",
    "    <li><a href=\"#Linear\">Class Linear</a></li>\n",
    "    <li><a href=\"#Cust\">Build Custom Modules</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:32:04.514676Z",
     "iopub.status.busy": "2025-05-24T13:32:04.514384Z",
     "iopub.status.idle": "2025-05-24T13:32:11.250357Z",
     "shell.execute_reply": "2025-05-24T13:32:11.248962Z",
     "shell.execute_reply.started": "2025-05-24T13:32:04.514651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Prediction\">Prediction</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the following expressions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b=-1,w=2$\n",
    "\n",
    "$\\hat{y}=-1+2x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define the parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:32:15.687467Z",
     "iopub.status.busy": "2025-05-24T13:32:15.686710Z",
     "iopub.status.idle": "2025-05-24T13:32:15.693533Z",
     "shell.execute_reply": "2025-05-24T13:32:15.692454Z",
     "shell.execute_reply.started": "2025-05-24T13:32:15.687432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(-1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define the function <code>forward(x, w, b)</code> makes the prediction: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:32:29.430728Z",
     "iopub.status.busy": "2025-05-24T13:32:29.430387Z",
     "iopub.status.idle": "2025-05-24T13:32:29.436379Z",
     "shell.execute_reply": "2025-05-24T13:32:29.435127Z",
     "shell.execute_reply.started": "2025-05-24T13:32:29.430697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make the following prediction at <i>x = 1</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{y}=-1+2x$\n",
    "\n",
    "$\\hat{y}=-1+2(1)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:32:39.508362Z",
     "iopub.status.busy": "2025-05-24T13:32:39.507956Z",
     "iopub.status.idle": "2025-05-24T13:32:39.610178Z",
     "shell.execute_reply": "2025-05-24T13:32:39.609171Z",
     "shell.execute_reply.started": "2025-05-24T13:32:39.508329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[1.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0]])\n",
    "yhat = forward(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try to make the prediction for multiple inputs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2.png\" width=\"500\" alt=\"Linear Regression Multiple Input Samples\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us construct the <code>x</code> tensor first. Check the shape of <code>x</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:33:35.507738Z",
     "iopub.status.busy": "2025-05-24T13:33:35.507098Z",
     "iopub.status.idle": "2025-05-24T13:33:35.515140Z",
     "shell.execute_reply": "2025-05-24T13:33:35.513674Z",
     "shell.execute_reply.started": "2025-05-24T13:33:35.507698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x:  torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0]])\n",
    "print(\"The shape of x: \", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make the prediction: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:33:42.843338Z",
     "iopub.status.busy": "2025-05-24T13:33:42.842905Z",
     "iopub.status.idle": "2025-05-24T13:33:42.852308Z",
     "shell.execute_reply": "2025-05-24T13:33:42.851205Z",
     "shell.execute_reply.started": "2025-05-24T13:33:42.843307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[1.],\n",
      "        [3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yhat = forward(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as what it is in the image above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:34:02.378423Z",
     "iopub.status.busy": "2025-05-24T13:34:02.378034Z",
     "iopub.status.idle": "2025-05-24T13:34:02.389802Z",
     "shell.execute_reply": "2025-05-24T13:34:02.388542Z",
     "shell.execute_reply.started": "2025-05-24T13:34:02.378395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [3.],\n",
       "        [5.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Linear\">Class Linear</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear class can be used to make a prediction. We can also use the linear class to build more complex models. Let's import the module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:34:40.339246Z",
     "iopub.status.busy": "2025-05-24T13:34:40.338584Z",
     "iopub.status.idle": "2025-05-24T13:34:40.345359Z",
     "shell.execute_reply": "2025-05-24T13:34:40.344177Z",
     "shell.execute_reply.started": "2025-05-24T13:34:40.338967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the random seed because the parameters are randomly initialized:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:34:45.159938Z",
     "iopub.status.busy": "2025-05-24T13:34:45.159598Z",
     "iopub.status.idle": "2025-05-24T13:34:45.175595Z",
     "shell.execute_reply": "2025-05-24T13:34:45.174274Z",
     "shell.execute_reply.started": "2025-05-24T13:34:45.159910Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e23807085d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i>. The parameters of an <code>torch.nn.Module</code> model are contained in the modelâ€™s parameters accessed with <code>lr.parameters()</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:34:53.539511Z",
     "iopub.status.busy": "2025-05-24T13:34:53.539135Z",
     "iopub.status.idle": "2025-05-24T13:34:53.551906Z",
     "shell.execute_reply": "2025-05-24T13:34:53.550119Z",
     "shell.execute_reply.started": "2025-05-24T13:34:53.539484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters w and b:  [Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "lr = Linear(in_features=1, out_features=1, bias=True)\n",
    "print(\"Parameters w and b: \", list(lr.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to the following expression:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b=-0.44, w=0.5153$\n",
    "\n",
    "$\\hat{y}=-0.44+0.5153x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method  <code>state_dict()</code> Returns a Python dictionary object corresponding to the layers of each parameter  tensor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:36:23.231280Z",
     "iopub.status.busy": "2025-05-24T13:36:23.230801Z",
     "iopub.status.idle": "2025-05-24T13:36:23.242499Z",
     "shell.execute_reply": "2025-05-24T13:36:23.241179Z",
     "shell.execute_reply.started": "2025-05-24T13:36:23.231242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python dictionary:  OrderedDict([('weight', tensor([[0.5153]])), ('bias', tensor([-0.4414]))])\n",
      "keys:  odict_keys(['weight', 'bias'])\n",
      "values:  odict_values([tensor([[0.5153]]), tensor([-0.4414])])\n"
     ]
    }
   ],
   "source": [
    "print(\"Python dictionary: \",lr.state_dict())\n",
    "print(\"keys: \",lr.state_dict().keys())\n",
    "print(\"values: \",lr.state_dict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys correspond to the name of the attributes and the values correspond to the parameter value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:36:55.829970Z",
     "iopub.status.busy": "2025-05-24T13:36:55.829671Z",
     "iopub.status.idle": "2025-05-24T13:36:55.837959Z",
     "shell.execute_reply": "2025-05-24T13:36:55.836894Z",
     "shell.execute_reply.started": "2025-05-24T13:36:55.829950Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True)\n",
      "bias: Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"weight:\", lr.weight)\n",
    "print(\"bias:\", lr.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us make a single prediction at <i>x = [[1.0]]</i>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:37:08.344820Z",
     "iopub.status.busy": "2025-05-24T13:37:08.342463Z",
     "iopub.status.idle": "2025-05-24T13:37:08.391819Z",
     "shell.execute_reply": "2025-05-24T13:37:08.390026Z",
     "shell.execute_reply.started": "2025-05-24T13:37:08.344764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.0739]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0]])\n",
    "yhat = lr(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can make multiple predictions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter2/2.1.2vector_function.png\" width=\"500\" alt=\"Linear Class Sample with Multiple Inputs\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model <code>lr(x)</code> to predict the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:37:16.860989Z",
     "iopub.status.busy": "2025-05-24T13:37:16.860693Z",
     "iopub.status.idle": "2025-05-24T13:37:16.870830Z",
     "shell.execute_reply": "2025-05-24T13:37:16.869445Z",
     "shell.execute_reply.started": "2025-05-24T13:37:16.860968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.0739],\n",
      "        [0.5891]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0]])\n",
    "yhat = lr(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>lr</code>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:37:54.507760Z",
     "iopub.status.busy": "2025-05-24T13:37:54.507445Z",
     "iopub.status.idle": "2025-05-24T13:37:54.516317Z",
     "shell.execute_reply": "2025-05-24T13:37:54.515340Z",
     "shell.execute_reply.started": "2025-05-24T13:37:54.507734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0739],\n",
       "        [0.5891],\n",
       "        [1.1044]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "lr(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Cust\">Build Custom Modules</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a custom module. We can make more complex models by using this method later on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the following library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:38:12.263645Z",
     "iopub.status.busy": "2025-05-24T13:38:12.262588Z",
     "iopub.status.idle": "2025-05-24T13:38:12.269529Z",
     "shell.execute_reply": "2025-05-24T13:38:12.268232Z",
     "shell.execute_reply.started": "2025-05-24T13:38:12.263608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define the class: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:39:05.497073Z",
     "iopub.status.busy": "2025-05-24T13:39:05.496669Z",
     "iopub.status.idle": "2025-05-24T13:39:05.503327Z",
     "shell.execute_reply": "2025-05-24T13:39:05.502303Z",
     "shell.execute_reply.started": "2025-05-24T13:39:05.497045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object by using the constructor. Print out the parameters we get and the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:39:07.190899Z",
     "iopub.status.busy": "2025-05-24T13:39:07.190554Z",
     "iopub.status.idle": "2025-05-24T13:39:07.200928Z",
     "shell.execute_reply": "2025-05-24T13:39:07.199338Z",
     "shell.execute_reply.started": "2025-05-24T13:39:07.190873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  [Parameter containing:\n",
      "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4694], requires_grad=True)]\n",
      "Linear model:  Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(1, 1)\n",
    "print(\"The parameters: \", list(lr.parameters()))\n",
    "print(\"Linear model: \", lr.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to make a prediction of a single input sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:39:32.315648Z",
     "iopub.status.busy": "2025-05-24T13:39:32.315339Z",
     "iopub.status.idle": "2025-05-24T13:39:32.322699Z",
     "shell.execute_reply": "2025-05-24T13:39:32.321759Z",
     "shell.execute_reply.started": "2025-05-24T13:39:32.315628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.2755]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0]])\n",
    "yhat = lr(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try another example with multiple samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:39:43.669258Z",
     "iopub.status.busy": "2025-05-24T13:39:43.668886Z",
     "iopub.status.idle": "2025-05-24T13:39:43.677442Z",
     "shell.execute_reply": "2025-05-24T13:39:43.676286Z",
     "shell.execute_reply.started": "2025-05-24T13:39:43.669233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction:  tensor([[0.2755],\n",
      "        [0.0816]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0]])\n",
    "yhat = lr(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parameters are also stored in an ordered dictionary :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:39:52.488516Z",
     "iopub.status.busy": "2025-05-24T13:39:52.488160Z",
     "iopub.status.idle": "2025-05-24T13:39:52.497825Z",
     "shell.execute_reply": "2025-05-24T13:39:52.496689Z",
     "shell.execute_reply.started": "2025-05-24T13:39:52.488490Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python dictionary:  OrderedDict([('linear.weight', tensor([[-0.1939]])), ('linear.bias', tensor([0.4694]))])\n",
      "keys:  odict_keys(['linear.weight', 'linear.bias'])\n",
      "values:  odict_values([tensor([[-0.1939]]), tensor([0.4694])])\n"
     ]
    }
   ],
   "source": [
    "print(\"Python dictionary: \", lr.state_dict())\n",
    "print(\"keys: \",lr.state_dict().keys())\n",
    "print(\"values: \",lr.state_dict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object <code>lr1</code> from the class we created before and make a prediction by using the following tensor: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T13:42:29.154729Z",
     "iopub.status.busy": "2025-05-24T13:42:29.154291Z",
     "iopub.status.idle": "2025-05-24T13:42:29.165345Z",
     "shell.execute_reply": "2025-05-24T13:42:29.164092Z",
     "shell.execute_reply.started": "2025-05-24T13:42:29.154698Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3417],\n",
       "        [-1.2832],\n",
       "        [-2.2246]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "lr1 = LinearRegression(1, 1)\n",
    "lr1(x)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "prev_pub_hash": "eb40c9132f5fb6974a287b8637f688ed48ef4a70d44648afa06d9cbdfb1d80b2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
